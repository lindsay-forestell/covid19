{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import pymc3 as pm\n",
    "#print('Running on PyMC3 v{}'.format(pm.__version__))\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "from sklearn.externals import joblib \n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_model(x, y):\n",
    "    \n",
    "    x = np.asarray(x).flatten()\n",
    "    y = np.asarray(y).flatten()\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        \n",
    "         # Priors for unknown model parameters\n",
    "        alpha = pm.Normal('alpha', mu=0, sigma=10)\n",
    "        beta = pm.Normal('beta', mu=0, sigma=10)\n",
    "        sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "\n",
    "        # Expected value of outcome\n",
    "        mu = alpha*pm.math.exp(beta*x)\n",
    "\n",
    "        # Likelihood (sampling distribution) of observations\n",
    "        y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)\n",
    "        \n",
    "    return model\n",
    "    \n",
    "def sig_model(x, y):\n",
    "    \n",
    "    x = np.asarray(x).flatten()\n",
    "    y = np.asarray(y).flatten()\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        \n",
    "         # Priors for unknown model parameters\n",
    "        alpha = pm.Normal('alpha', mu=0, sigma=10)\n",
    "        beta = pm.Normal('beta', mu=0, sigma=10, shape=2)\n",
    "        sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "\n",
    "        # Expected value of outcome\n",
    "        mu = alpha/(1+pm.math.exp(-(beta[0]*x+beta[1])))\n",
    "\n",
    "        # Likelihood (sampling distribution) of observations\n",
    "        y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)\n",
    "        \n",
    "    return model\n",
    "        \n",
    "def predict_model(model, trace_path, samples):\n",
    "    \n",
    "    with model:\n",
    "        \n",
    "        trace = pm.load_trace(directory = trace_path)\n",
    "        y_hat = pm.sample_posterior_predictive(trace, samples=samples, progressbar=False)\n",
    "        \n",
    "    return y_hat['y_obs']\n",
    "\n",
    "# arbitrary country\n",
    "def get_country(country, start_date='', end_date='', min_cases=10):\n",
    "\n",
    "    url = 'https://www.worldometers.info/coronavirus/country/'+country.lower()+'/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    test= soup.find('script', text=re.compile('Total Coronavirus Cases'))\n",
    "    save_stuff = False\n",
    "    for line in test.get_text().split('\\n'):\n",
    "        if 'text' in line:\n",
    "            if 'Linear Scale' in line or 'Total Coronavirus Cases' in line:\n",
    "                save_stuff = True\n",
    "            else:\n",
    "                save_stuff = False\n",
    "        if 'categories' in line:\n",
    "            if save_stuff:\n",
    "                categories = line.split(',')\n",
    "                categories[0] = categories[0][25:]\n",
    "                categories = categories[:-1]\n",
    "                categories[-1] = categories[-1].strip('}').strip(' ').strip(']')\n",
    "                categories = [x.strip('\"') for x in categories]\n",
    "        if 'data' in line:\n",
    "            if save_stuff:\n",
    "                data = line.split(',')\n",
    "                data[0] = data[0][19:]\n",
    "                data = data[:-1]\n",
    "                data[-1] = data[-1].strip(']').strip('}').strip(' ').strip(']')\n",
    "                data = [int(x) for x in data]\n",
    "                \n",
    "    start = np.where(np.array(categories)==start_date)[0]\n",
    "    if len(start)==0:\n",
    "        start = 0\n",
    "    else:\n",
    "        start = start[0]\n",
    "        \n",
    "    end = np.where(np.array(categories)==end_date)[0]\n",
    "    if len(end)==0:\n",
    "        end = len(categories)-1\n",
    "    else:\n",
    "        end = end[0]\n",
    "    \n",
    "    dates = categories[start:end+1]\n",
    "    data = data[start:end+1]\n",
    "    \n",
    "    if max(data)<min_cases:\n",
    "        print('Warning, {:d} cases has not occured in this date range.')\n",
    "    else:\n",
    "        min_start = np.where(np.array(data)>=min_cases)[0][0]\n",
    "        data = data[min_start:]\n",
    "        dates = dates[min_start:]\n",
    "    \n",
    "    return dates, np.arange(1, len(data)+1), np.array(data)\n",
    "\n",
    "def scale_data(x, y):\n",
    "    x_train = np.array(x[:-3])\n",
    "    y_train = np.array(y[:-3])\n",
    "\n",
    "    x_test = np.array(x[-3:])\n",
    "    y_test = np.array(y[-3:])\n",
    "\n",
    "    # rescale y\n",
    "    scaler = MinMaxScaler(feature_range = (0.1, 0.8))\n",
    "    y_scale = scaler.fit_transform(y_train.reshape(-1,1)).flatten()\n",
    "\n",
    "    # rescale x?\n",
    "    scalex = MinMaxScaler()\n",
    "    x_scale = scalex.fit_transform(x_train.reshape(-1,1)).flatten()\n",
    "    \n",
    "    return x_train, y_train, x_scale, y_scale, x_test, y_test, scaler, scalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country(country, num_days, ymax):\n",
    "\n",
    "    #dates, x, y = get_country(country, min_cases=100)\n",
    "\n",
    "    tr_path = os.path.join('traces', country.lower())\n",
    "    \n",
    "    dates = joblib.load(os.path.join(tr_path, 'dates.pkl'))\n",
    "    x = joblib.load(os.path.join(tr_path, 'x.pkl'))\n",
    "    y = joblib.load(os.path.join(tr_path, 'y.pkl'))\n",
    "    \n",
    "    scalex = joblib.load(os.path.join(tr_path,'scalex.pkl'))\n",
    "    scaley = joblib.load(os.path.join(tr_path, 'scaley.pkl'))\n",
    "\n",
    "    x_scale = scalex.transform(x.reshape(-1,1)).flatten()\n",
    "    y_scale = scaley.transform(y.reshape(-1,1)).flatten()\n",
    "\n",
    "    x_train = x[:-3]\n",
    "    x_test = x[-3:]\n",
    "\n",
    "    y_train = y[:-3]\n",
    "    y_test = y[-3:]\n",
    "    \n",
    "    last = len(x)\n",
    "    num_days = num_days\n",
    "    extend = np.arange(last+1, last+num_days+1)\n",
    "    x_updated = np.append(x, extend)\n",
    "    x_updated_scaled = scalex.transform(x_updated.reshape(-1, 1)).flatten()\n",
    "    y_updated = np.empty(x_updated.shape)\n",
    "\n",
    "    exp_updated = exp_model(x_updated_scaled, y_updated)\n",
    "    sig_updated = sig_model(x_updated_scaled, y_updated)\n",
    "\n",
    "    y_exp = predict_model_from_file(exp_updated, os.path.join(tr_path, 'exp'), 1000)\n",
    "    y_sig = predict_model_from_file(sig_updated, os.path.join(tr_path, 'sig'), 1000)\n",
    "\n",
    "    y_exp_avg = np.mean(y_exp, axis=0).reshape(-1,1)\n",
    "    y_exp_std = 2*np.std(y_exp, axis=0).reshape(-1,1)\n",
    "\n",
    "    y_sig_avg = np.mean(y_sig, axis=0).reshape(-1,1)\n",
    "    y_sig_std = 2*np.std(y_sig, axis=0).reshape(-1,1)\n",
    "\n",
    "    y_exp_high = scaley.inverse_transform(y_exp_avg+y_exp_std).flatten()\n",
    "    y_exp_low = scaley.inverse_transform(y_exp_avg-y_exp_std).flatten()\n",
    "\n",
    "    y_sig_high = scaley.inverse_transform(y_sig_avg+y_sig_std).flatten()\n",
    "    y_sig_low = scaley.inverse_transform(y_sig_avg-y_sig_std).flatten()\n",
    "    \n",
    "    plt.figure(figsize = (10,8))\n",
    "    plt.fill_between(x_updated, y_exp_high, y_exp_low, alpha = 0.5, label='Exponential')\n",
    "    plt.fill_between(x_updated, y_sig_high, y_sig_low, alpha = 0.5, label='Sigmoid')\n",
    "    plt.scatter(x_train, y_train, label='Training Data')\n",
    "    plt.scatter(x_test, y_test, label='Last 3 Days')\n",
    "    plt.vlines(last+1, -0.5, max(y)+100*max(y), label='Most Recent Unknown')\n",
    "    \n",
    "    if ymax == -1:\n",
    "        ymax = max(y)+3*max(y)\n",
    "    plt.ylim([-0.5, ymax])\n",
    "    plt.xlim([x_updated[0], x_updated[-1]])\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(country.upper()+' -- DAY ONE = {:s}'.format(dates[0].upper()))\n",
    "    plt.xlabel('Days since hitting 100 cases.')\n",
    "    plt.ylabel('Total number of cases.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e086272a987405cbe71f746090b5ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Country:', options=('Italy', 'Germany', 'China', 'Spain', 'Canada'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "country_list = ['Italy', 'Germany', 'China', 'Spain', 'Canada', 'US']\n",
    "\n",
    "country_widget= widgets.Dropdown(\n",
    "    options=country_list,\n",
    "    value='Italy',\n",
    "    description='Country:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "num_days_widget = widgets.IntText(\n",
    "    value=7,\n",
    "    step=1,\n",
    "    description='Number of Future Days:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "ymax_widget = widgets.IntText(\n",
    "    value=-1,\n",
    "    description='Y Max:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "out = interact_manual(plot_country, country=country_widget, num_days=num_days_widget, ymax = ymax_widget)\n",
    "#plot_country('Italy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
